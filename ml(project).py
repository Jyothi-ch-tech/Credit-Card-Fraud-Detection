# -*- coding: utf-8 -*-
"""ML(project).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/199a5aIiiJuSEz2T9m2iXUTKY6hxfaIHo

# ***Credit Card Fraud Detection using ML***

1.  Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from imblearn.over_sampling import SMOTE

"""2. Load Dataset"""

df=pd.read_csv('/content/creditcard.csv')

# Drop missing values if any
df.dropna(inplace=True)

#Check for nulls
print(df.isnull().sum())

print(df.head())
print(df['Class'].value_counts())

""" 3.Preprocessing"""

# Standardize 'Amount' and drop 'Time' if present
if 'Amount' in df.columns:
    df['Amount'] = StandardScaler().fit_transform(df[['Amount']])
if 'Time' in df.columns:
    df.drop('Time', axis=1, inplace=True)

# Features and target
X = df.drop('Class', axis=1)
y = df['Class']

"""4. Train-Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

"""5. Handle Imbalance with SMOTE"""

#Handle Imbalanced Data using SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

"""6. Train ML Models

Logistic Regression AND  Random Forest
"""

# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_res, y_train_res)
y_pred_lr = lr.predict(X_test)

# Random Forest (optimized)
rf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)
rf.fit(X_train_res[:20000], y_train_res[:20000])  # Speed up training
y_pred_rf = rf.predict(X_test)

"""7. Evaluate Models"""

def evaluate_model(y_true, y_pred, model_name):
    print(f"\n {model_name} Results:")
    print(confusion_matrix(y_true, y_pred))
    print(classification_report(y_true, y_pred))
    print("ROC AUC Score:", roc_auc_score(y_true, y_pred))

evaluate_model(y_test, y_pred_lr, "Logistic Regression")
evaluate_model(y_test, y_pred_rf, "Random Forest")

"""8. Visualize Confusion Matrix"""

sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')
plt.title("Random Forest Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Simulate a new transaction (using any existing one)
new_data = X.iloc[100].values.reshape(1, -1)
# Predict using Logistic Regression
lr_result = lr.predict(new_data)
print("Logistic Regression:", "Fraud" if lr_result[0] == 1 else "Legit")
rf_result = rf.predict(new_data)
print("Random Forest:", "Fraud" if rf_result[0] == 1 else "Legit")

# Manually create a new fraudulent transaction
# Example: [Time, V1, V2, ..., V28, Amount]
new_fraud_data = np.array([0, 1.2, 0.5, -1.1, 0.9, 0.6, 0.4, -1.2, 0.8, 0.7, 1.1, -0.6, 0.3, -0.5, 1.0, 0.4, -1.0, -0.3, 0.6, 0.1, 0.8, -0.7, -1.3, 0.9, 1.2, 0.5, 0.2, -0.4, 50.0])
new_fraud_data = new_fraud_data.reshape(1, -1)
# Predict with Logistic Regression
lr_result = lr.predict(new_fraud_data)
print("Logistic Regression:", "Fraud" if lr_result[0] == 1 else "Legit")
# Predict with Random Forest
rf_result = rf.predict(new_fraud_data)
print("Random Forest:", "Fraud" if rf_result[0] == 1 else "Legit")

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Predict probabilities
lr_probs = lr.predict_proba(X_test)[:, 1]
rf_probs = rf.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_probs)
roc_auc_lr = auc(fpr_lr, tpr_lr)

fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probs)
roc_auc_rf = auc(fpr_rf, tpr_rf)

# Plot ROC curves
plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-AUC Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def print_metrics(y_true, y_pred, model_name):
    print(f"\n {model_name} Metrics")
    print(f"Accuracy : {accuracy_score(y_true, y_pred):.4f}")
    print(f"Precision: {precision_score(y_true, y_pred):.4f}")
    print(f"Recall   : {recall_score(y_true, y_pred):.4f}")
    print(f"F1 Score : {f1_score(y_true, y_pred):.4f}")

# Predictions
y_pred_lr = lr.predict(X_test)
y_pred_rf = rf.predict(X_test)

# Evaluate both models
print_metrics(y_test, y_pred_lr, "Logistic Regression")
print_metrics(y_test, y_pred_rf, "Random Forest")